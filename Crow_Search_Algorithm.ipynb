{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import time\n",
        "\n",
        "# Load your dataset from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_path = '/content/drive/My Drive/wireless/NF-BOT-IOT_train_preprocessed.csv'\n",
        "test_path = '/content/drive/My Drive/wireless/NF-BOT-IOT_test_preprocessed.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "test_data = pd.read_csv(test_path)\n",
        "train_data = train_data.dropna(subset=['label'])\n",
        "test_data = test_data.dropna(subset=['label'])\n",
        "\n",
        "X_train = train_data.drop(columns=['label'], axis=1)\n",
        "y_train = train_data['label']\n",
        "X_test = test_data.drop(columns=['label'], axis=1)\n",
        "y_test = test_data['label']\n",
        "\n",
        "# Define the Crow Search Algorithm class\n",
        "class CrowSearchAlgorithm:\n",
        "    def __init__(self, population_size=5, max_iter=3, fl=0.5, ap=0.1):\n",
        "        self.population_size = population_size\n",
        "        self.max_iter = max_iter\n",
        "        self.fl = fl  # Flight length\n",
        "        self.ap = ap  # Awareness probability\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        start_time = time.time()\n",
        "        num_features = X.shape[1]\n",
        "        positions = np.random.randint(0, 2, size=(self.population_size, num_features), dtype=bool)\n",
        "        fitness_memory = np.zeros(self.population_size)\n",
        "\n",
        "        for i in range(self.population_size):\n",
        "            fitness_memory[i] = self.fitness(X.iloc[:, positions[i]], y)\n",
        "\n",
        "        best_idx = np.argmax(fitness_memory)\n",
        "        best_features = positions[best_idx, :]\n",
        "\n",
        "        for iteration in range(self.max_iter):\n",
        "            for i in range(self.population_size):\n",
        "                new_pos = positions[i].copy()\n",
        "                if np.random.rand() < self.ap:\n",
        "                    new_pos ^= (np.random.rand(num_features) < self.fl)\n",
        "                else:\n",
        "                    new_pos ^= (positions[best_idx] ^ (np.random.rand(num_features) < self.fl))\n",
        "\n",
        "                new_fit = self.fitness(X.iloc[:, new_pos], y)\n",
        "                if new_fit > fitness_memory[i]:\n",
        "                    positions[i] = new_pos\n",
        "                    fitness_memory[i] = new_fit\n",
        "                    if new_fit > fitness_memory[best_idx]:\n",
        "                        best_idx = i\n",
        "\n",
        "        execution_time = time.time() - start_time\n",
        "        return positions[best_idx], execution_time\n",
        "\n",
        "    def fitness(self, X_subset, y):\n",
        "        if X_subset.empty:\n",
        "            return 0\n",
        "        clf = make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs', max_iter=1000))\n",
        "        clf.fit(X_subset, y)\n",
        "        return accuracy_score(y, clf.predict(X_subset))\n",
        "\n",
        "# Instantiate and run the CSA for feature selection\n",
        "csa = CrowSearchAlgorithm()\n",
        "best_features_mask, exec_time = csa.fit(X_train, y_train)\n",
        "best_features = X_train.columns[best_features_mask]\n",
        "\n",
        "# Print and save selected features\n",
        "print(\"Selected features by CSA:\", best_features.tolist())\n",
        "filename = \"NF-BOT-IOT_CSA_features.csv\"\n",
        "with open(filename, 'w') as file:\n",
        "    file.write(f\"Algorithm,Execution Time,Number of Features,Feature Names\\n\")\n",
        "    file.write(f\"CSA,{exec_time},{len(best_features)},{' '.join(best_features)}\\n\")\n",
        "\n",
        "# Filter the training and testing data\n",
        "X_train_selected = X_train.loc[:, best_features]\n",
        "X_test_selected = X_test.loc[:, best_features]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w80ao_TE1zuZ",
        "outputId": "f7b233de-d925-43c8-cddf-bd9238fea00e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Selected features by CSA: ['L4_DST_PORT', 'PROTOCOL', 'L7_PROTO', 'FLOW_DURATION_MILLISECONDS']\n"
          ]
        }
      ]
    }
  ]
}